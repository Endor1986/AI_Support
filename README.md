<p align="center">
  <img alt="Next.js" src="https://img.shields.io/badge/Next.js-14-000000?logo=nextdotjs&logoColor=white">
  <img alt="TypeScript" src="https://img.shields.io/badge/TypeScript-5.x-3178C6?logo=typescript&logoColor=white">
  <img alt="Node.js" src="https://img.shields.io/badge/Node.js-18%2F20%2B-339933?logo=node.js&logoColor=white">
  <img alt="Streaming" src="https://img.shields.io/badge/Streaming-SSE-1f6feb">
  <img alt="Zod" src="https://img.shields.io/badge/Schema-Zod-3a86ff">
  <img alt="Status" src="https://img.shields.io/badge/Status-MVP-success">
  <img alt="Rights" src="https://img.shields.io/badge/Rights-All%20rights%20reserved-lightgrey">
</p>

# AI_Support (Next.js + TypeScript)

Minimaler Prototyp fÃ¼r eine Support-AI mit **Triage â†’ Antwort â†’ optionalem Streaming (SSE)**.  
Lokal ohne echten API-Key testbar (**Dummy-Modus**).

---

## âœ¨ Features
- `POST /api/support/triage` â†’ strukturiertes JSON (**intent / entities / urgency**), **Zod-Validierung**, einfache **PII-Redaktion**
- `POST /api/support/reply` â†’ kurze, hÃ¶fliche Antwort (DE/EN), optionaler Tool-Kontext (Order-Status Mock)
- `POST /api/support/reply/stream` â†’ **SSE**-Ã¤hnliches Live-Streaming
- **Frontend**: minimale Seite (Textarea + Buttons), klare Fehlermeldungen
- **Dummy-Modus**: komplett offline testbar (kein OpenAI erforderlich)

---

## ğŸ—‚ Projektstruktur
```
AI_SUPPORT/
â”œâ”€ app/
â”‚  â”œâ”€ api/
â”‚  â”‚  â””â”€ support/
â”‚  â”‚     â”œâ”€ triage/route.ts          # Triage (Dummy + OpenAI structured output)
â”‚  â”‚     â”œâ”€ reply/route.ts           # Antwort (Dummy + OpenAI)
â”‚  â”‚     â””â”€ reply/stream/route.ts    # Streaming (Dummy + OpenAI stream)
â”‚  â”œâ”€ api/debug/env/route.ts         # (optional) Key-Check (lokal)
â”‚  â””â”€ page.tsx                       # Simple UI (Textarea + Buttons)
â”œâ”€ .env.example
â”œâ”€ next.config.mjs
â”œâ”€ package.json
â””â”€ README.md
```
_Screenshots zum MVP findest du im Ordner `docs/screens`._

---

## âš™ï¸ Voraussetzungen
- **Node.js 18/20+**
- **npm** (oder pnpm/yarn)
- Optional: **OPENAI_API_KEY**, falls echte LLM-Antworten gewÃ¼nscht sind

---

## ğŸš€ Schnellstart
```bash
cp .env.example .env.local
# FÃ¼r lokalen Test ohne API:
# USE_DUMMY_AI=true in .env.local

npm i
npm run dev
# Browser: http://localhost:3000
```

---

## ğŸ”§ Umgebungsvariablen
```ini
# FÃ¼r echten LLM-Betrieb (optional)
OPENAI_API_KEY=sk-REPLACE_ME
OPENAI_MODEL=gpt-4o-mini

# FÃ¼r lokalen Test ohne API
USE_DUMMY_AI=true
```

---

## ğŸ›£ API

### POST `/api/support/triage`
**Request**
```json
{ "message": "Hallo, wo ist Bestellung A12345?" }
```
**Response (Beispiel)**
```json
{
  "intent": "order_status",
  "urgency": "low",
  "entities": { "orderId": "A12345" },
  "language": "de",
  "confidence": 0.9
}
```
**Hinweis:** Order-ID Heuristik: `Aâ€“Z`, `0â€“9`, `-`, mind. **eine Ziffer**, LÃ¤nge **5â€“24** (anpassbar).

### POST `/api/support/reply`
**Request**
```json
{
  "message": "Status zu Bestellung A12345",
  "triage": {
    "intent": "order_status",
    "urgency": "low",
    "entities": { "orderId": "A12345" },
    "language": "de",
    "confidence": 0.9
  }
}
```
**Response (Beispiel)**
```json
{ "reply": "Danke fÃ¼r Ihre Anfrage. Ihre Bestellung A12345 ist unterwegs (DHL, Tracking: 00340434123DE)." }
```

### POST `/api/support/reply/stream`
**Request**
```json
{
  "message": "Status zu Bestellung A12345",
  "triage": {
    "intent": "order_status",
    "urgency": "low",
    "entities": { "orderId": "A12345" },
    "language": "de",
    "confidence": 0.9
  }
}
```
**Response:** `Content-Type: text/plain` â€“ Tokens werden fortlaufend gestreamt (Dummy oder OpenAI-Stream).

---

## ğŸ§ª CLI-Tests
```bash
# Triage
curl -s -X POST http://localhost:3000/api/support/triage   -H "Content-Type: application/json"   -d '{"message":"Hallo, wo ist Bestellung A12345?"}'

# Antwort
curl -s -X POST http://localhost:3000/api/support/reply   -H "Content-Type: application/json"   -d '{"message":"Status zu Bestellung A12345","triage":{"intent":"order_status","urgency":"low","entities":{"orderId":"A12345"},"language":"de","confidence":0.9}}'

# Streaming
curl -N -X POST http://localhost:3000/api/support/reply/stream   -H "Content-Type: application/json"   -d '{"message":"Status zu Bestellung A12345","triage":{"intent":"order_status","urgency":"low","entities":{"orderId":"A12345"},"language":"de","confidence":0.9}}'
```

---

## ğŸ›  Troubleshooting
- **HTTP 500 bei Triage/Reply** â†’ `USE_DUMMY_AI=true` setzen, Server neu starten.
- **`invalid_api_key`** â†’ vollstÃ¤ndigen `sk-...` Key eintragen (nicht die gekÃ¼rzte Anzeige).
- **Key-Check (lokal)** â†’ `GET /api/debug/env` sollte `{ "hasKey": true }` liefern.
- **Node 22-Eigenheiten** â†’ ggf. Node 20 LTS testen.

---

## ğŸ“„ Changelog
Der Changelog liegt unter **`docs/CHANGELOG.md`**.

---

## ğŸ”’ Rechte / Lizenzhinweis
Alle Rechte vorbehalten.  
Dieses Repository ist fÃ¼r Lern-/Demo-Zwecke vorgesehen und **nicht** zur produktiven Verwendung freigegeben.
